// SPDX-License-Identifier: MIT

:	reg

//// register
reg:	REG		== %r0
reg:	ARG		== %r0
reg:	UNDEF
reg:	VOID

zreg:	reg		== %r0
zreg:	zero		== %r0

//// constants
zero:	CONST		if %c == 0

imm5:	CONST		if range(%c, 0, 31)
nmm5:	CONST		if range(%c, -31, 0)

simm:	CONST		if (masked_range(%c, 0, 0, 4095) || masked_range(%c, 12, 0, 4095))
nimm:	CONST		if masked_range(%c, 0, -4096, -1)

pimm8:	CONST		if masked_range(%c, 3, 0, 4095)
pimm4:	CONST		if masked_range(%c, 2, 0, 4095)
pimm2:	CONST		if masked_range(%c, 1, 0, 4095)
pimm1:	CONST		if masked_range(%c, 0, 0, 4095)

wimm:	CONST		if wide_immediate(%c)
bimm32:	CONST		if bitmask(%c, 32)
bimm64:	CONST		if bitmask(%c, 64)
vimm:	CONST		if inverted_immediate(%c)
imm32:	CONST		if range(%c, 0, 0xffffffff)
imm48:	CONST		if range(%c, 0, 0xffffffffffffULL)

bit:	CONST		if power_of_two(%c)

one:	CONST		if %c == 1
ones32:	CONST		if %c == 0xffffffff
ones64:	CONST		if %c == 0xffffffffffffffffULL


// !!! WARNING !!! this '%rt' things is an horrible hackery
reg:	bimm32		[1] => mov	%rt, #%c0
reg:	bimm64		[1] => mov	%rt, #%c0
reg:	wimm		[1] => mov	%rt, #%c0
reg:	vimm		[1] => movn	%rt, #%c0

			// FIXME
reg:	imm32		[2] => movz	%rt, #%cl0; movk\t%rt, #%cu0, lsl #16
reg:	imm48		[3] => movz	%rt, #%cl0; movk\t%rt, #%cu0, lsl #16; movk\t%rt, #%cL0, lsl #32
reg:	CONST		[4] => movz	%rt, #%cl0; movk\t%rt, #%cu0, lsl #16; movk\t%rt, #%cL0, lsl #32; movk\t%rt, #%cU0, lsl #48

// TODO: all other constants synthesis

reg:	COPY(wimm)	[1] => mov	%rd, #%c1
reg:	COPY.L(bimm32)	[1] => mov	%rd, #%c1
reg:	COPY.Q(bimm64)	[1] => mov	%rd, #%c1
reg:	COPY(vimm)	[1] => movn	%rd, #%c1
reg:	COPY(imm32)	[2] => movz	%rd, #%cl1; movk\t%rd, #%cu1
reg:	COPY(imm48)	[3] => movz	%rd, #%cl1; movk\t%rd, #%cu1, lsl #16; movk\t%rd, #%cL1, lsl #32
reg:	COPY(CONST)	[4] => movz	%rd, #%cl1; movk\t%rd, #%cu1, lsl #16; movk\t%rd, #%cL1, lsl #32; movk\t%rd, #%cU1, lsl #48


reg:	COPY(reg)	[1] => mov	%rd, %r1

			// 'adr' is enough if label within +- 1MB
reg:	SETVAL		[2] => adrp	%rd, %x; add	%rd, %rd, :lo12:%x
reg:	LABEL		[2] => adrp	%rd, %b; add	%rd, %rd, :lo12:%b


//// shifted register for arithmetic instructions
sh:	CONST
sreg:	reg		    == %r0
sreg:	SHL(reg, sh)	    == %r1, lsl #%c2
sreg:	LSR(reg, sh)	    == %r1, lsr #%c2
sreg:	ASR(reg, sh)	    == %r1, asr #%c2

//// shifted register for logical instructions
lreg:	reg		    == %r0
lreg:	SHL(reg, sh)	    == %r1, lsl #%c2
lreg:	LSR(reg, sh)	    == %r1, lsr #%c2
lreg:	ASR(reg, sh)	    == %r1, asr #%c2
lreg:	ROR(reg, sh)	    == %r1, ror #%c2

//// extended register
xsh:	CONST		if range(%c, 0, 4)
xt:	ZEXT(reg,#B)	    == %r1, uxtb
xt:	ZEXT(reg,#H)	    == %r1, uxth
xt:	ZEXT(reg,#L)	    == %r1, uxtw
xt:	SEXT(reg,#B)	    == %r1, sxtb
xt:	SEXT(reg,#H)	    == %r1, sxth
xt:	SEXT(reg,#L)	    == %r1, sxtw
xreg:	SHL.L(reg,xsh)	    == %r1, uxtw #%c2
xreg:	SHL.Q(reg,xsh)	    == %r1, uxtx #%c2
xreg:	SHL(xt, xsh)	    == %a1 #%c2
xreg:	xt		    == %a0

//// any/arithmetic register mode
areg:	reg		    == %r0
areg:	sreg		    == %a0
areg:	xreg		    == %a0

//// arithmetic
reg:	ADD(reg, simm)	[1] => add	%rd, %r1, #%c2
reg:	ADD(reg, areg)	[1] => add	%rd, %r1, %a2
reg:	ADD(areg, reg)	[1] => add	%rd, %r2, %a1
reg:	SUB(reg, simm)	[1] => sub	%rd, %r1, #%c2
reg:	SUB(reg, areg)	[1] => sub	%rd, %r1, %a2
reg:	NEG(sreg)	[1] => neg	%rd, %a1

//// multiply/divide (FIXME: cost depends on size)
mul:	MUL.L(reg, reg)	    == %r1, %r2
mul:	MUL.Q(reg, reg)	    == %r1, %r2
reg:	mul		[5] => mul	%rd, %a0
reg:	ADD(mul,reg)	[5] => madd	%rd, %a1, %r2
reg:	ADD(reg, mul)	[5] => madd	%rd, %a2, %r1
reg:	SUB(reg, mul)	[5] => msub	%rd, %a2, %r1
reg:	NEG(mul)	[5] => mneg	%rd, %a1

sxl:	SEXT(reg,#L)	== %r1
smull:	MUL(sxl,sxl)	== %a1, %a2
reg:	smull			[3] => smull	%rd, %a0
reg:	ADD(smull, reg)		[3] => smaddl	%rd, %a1, %r2
reg:	ADD(reg, smull)		[3] => smaddl	%rd, %a2, %r1
reg:	SUB(reg, smull)		[3] => smsubl	%rd, %a2, %r1
reg:	NEG(smull)		[3] => smnegl	%rd, %a1

zxl:	ZEXT(reg,#L)	== %r1
umull:	MUL(zxl,zxl)	== %a1, %a2
reg:	umull			[3] => umull	%rd, %a0
reg:	ADD(umull, reg)		[3] => umaddl	%rd, %a1, %r2
reg:	ADD(reg, umull)		[3] => umaddl	%rd, %a2, %r1
reg:	SUB(reg, umull)		[3] => umsubl	%rd, %a2, %r1
reg:	NEG(umull)		[3] => umnegl	%rd, %a1

// 64x64 -> low(64), high(64)
reg:	MULHS.Q(reg,reg)	[5] => smulh	%rd, %r1, %r2
reg:	MULHU.Q(reg,reg)	[5] => umulh	%rd, %r1, %r2

zxq:	ZEXT(reg,#Q)	== %r1
umulq:	MUL(zxq,zxq)	== %a1, %a2
sxq:	SEXT(reg,#Q)	== %r1
smulq:	MUL(sxq,sxq)	== %a1, %a2

reg:	TRUNC(umulq, #Q)	[5] => mul	%rd, %a1
reg:	TRUNC(smulq, #Q)	[5] => mul	%rd, %a1 // FIXME: should not be needed

// 64x64 -> high(64)
reg:	TRUNC(ASR(smulq,#Q),#Q)	[5] => smulh	%rd, %a11
reg:	TRUNC(LSR(umulq,#Q),#Q)	[5] => umulh	%rd, %a11

reg:    DIVS(reg, reg)	[36] => sdiv	%rd, %r1, %r2
reg:    DIVU(reg, reg)	[36] => udiv	%rd, %r1, %r2
reg:    MODS(reg, reg)	[41] => sdiv	%rt, %r1, %r2; msub	%rd, %rt, %r2, %r1
reg:    MODU(reg, reg)	[41] => udiv	%rt, %r1, %r2; msub	%rd, %rt, %r2, %r1

//// logical
nreg:	NOT(lreg)	== %a1
reg:	NOT(lreg)		[1] => mvn	%rd, %a1
reg:	AND.L(reg, bimm32)	[1] => and	%rd, %r1, #%c2
reg:	AND.Q(reg, bimm64)	[1] => and	%rd, %r1, #%c2
reg:	AND(reg, lreg)		[1] => and	%rd, %r1, %a2
reg:	AND(lreg, reg)		[1] => and	%rd, %r2, %a1
reg:	AND(reg, nreg)		[1] => bic	%rd, %r1, %a2
reg:	AND(nreg, reg)		[1] => bic	%rd, %r2, %a1
reg:	OR.L(reg, bimm32)	[1] => orr	%rd, %r1, #%c2
reg:	OR.Q(reg, bimm64)	[1] => orr	%rd, %r1, #%c2
reg:	OR(reg, lreg)		[1] => orr	%rd, %r1, %a2
reg:	OR(lreg, reg)		[1] => orr	%rd, %r2, %a1
reg:	OR(reg, nreg)		[1] => orn	%rd, %r1, %a2
reg:	OR(nreg, reg)		[1] => orn	%rd, %r2, %a1
reg:	XOR.L(reg, bimm32)	[1] => eor	%rd, %r1, #%c2
reg:	XOR.Q(reg, bimm64)	[1] => eor	%rd, %r1, #%c2
reg:	XOR(reg, lreg)		[1] => eor	%rd, %r1, %a2
reg:	XOR(lreg, reg)		[1] => eor	%rd, %r2, %a1
reg:	XOR(reg, nreg)		[1] => eon	%rd, %r1, %a2
reg:	XOR(nreg, reg)		[1] => eon	%rd, %r2, %a1
reg:	NOT(XOR(reg, lreg))	[1] => eon	%rd, %r11, %a12
reg:	NOT(XOR(lreg, reg))	[1] => eon	%rd, %r12, %a11

//// shift/rotate
sh:	CONST		// FIXME
reg:	SHL(reg, sh)	[1] => lsl	%rd, %r1, #%c2
reg:	SHL(reg, reg)	[1] => lslv	%rd, %r1, %r2
reg:	LSR(reg, sh)	[1] => lsr	%rd, %r1, #%c2
reg:	LSR(reg, reg)	[1] => lsrv	%rd, %r1, %r2
reg:	ASR(reg, sh)	[1] => asr	%rd, %r1, #%c2
reg:	ASR(reg, reg)	[1] => asrv	%rd, %r1, %r2
reg:	ROR(reg, sh)	[1] => ror	%rd, %r1, #%c2
reg:	ROR(reg, reg)	[1] => rorv	%rd, %r1, %r2

//// sign/zero extension & truncation
reg:	ZEXT(reg,#B)	[1] => and	%rd, %r1, #%m2
reg:	ZEXT(reg,#H)	[1] => and	%rd, %r1, #%m2
reg:	ZEXT(reg,#L)	[1] => uxtw	%rd, %r1
reg:	ZEXT(reg, sh)	[1] => ubfx	%rd, %r1, #0, #%c2
reg:	SEXT(reg,#B)	[1] => sxtb	%rd, %r1
reg:	SEXT(reg,#H)	[1] => sxth	%rd, %r1
reg:	SEXT(reg,#L)	[1] => sxtw	%rd, %r1
reg:	SEXT(reg, sh)	[1] => sbfx	%rd, %r1, #0, #%c2

reg:	TRUNC(reg, sh)	[1] => and	%rd, %r1, #%m2

//// bitfield extraction/insertion
lsr:	LSR(reg, sh)	== %r1, #%c1
reg:	ZEXT(lsr, sh)		[1] => ubfx	%rd, %r11, #%c12, #%c2
reg:	ZEXT(TRUNC(lsr,sh),sh)	[1] => ubfx	%rd, %r111, #%c112, #%c2

reg:	SEXT(TRUNC(reg,sh),sh)	[1] => sbfx	%rd, %r11, #0, #%c2
reg:	SEXT(lsr, sh)		[1] => sbfx	%rd, %r11, #%c12, #%c2
reg:	SEXT(TRUNC(lsr,sh),sh)	[1] => sbfx	%rd, %r111, #%c112, #%c2

reg:	LSR(SHL(reg,sh),sh) [1] if (%c2 < %c12) => ubfiz	%rd, %r11, #(%c12-%c2), #(%#-%c12)
reg:	ASR(SHL(reg,sh),sh) [1] if (%c2 < %c12) => sbfiz	%rd, %r11, #(%c12-%c2), #(%#-%c12)
reg:	LSR(SHL(reg,sh),sh) [1] if (%c2 > %c12) => ubfx	%rd, %r11, #(%c2-%c12), #(%#-%c2)
reg:	ASR(SHL(reg,sh),sh) [1] if (%c2 > %c12) => sbfx	%rd, %r11, #(%c2-%c12), #(%#-%c2)

//// slicing:
reg:	ZEXT(SLICE(reg, zero),#B)	[1] => 	and	%rd, %r11, #%m2
reg:	ZEXT(SLICE(reg, zero),#H)	[1] => 	and	%rd, %r11, #%m2
reg:	ZEXT(SLICE(reg, zero),#L)	[1] => 	and	%rd, %r11, #%m2
reg:	ZEXT(SLICE(reg, zero), sh)	[1] => 	ubfx	%rd, %r11, #%c12, #%c2
reg:	SEXT(SLICE(reg, zero), sh)	[1] => 	sbfx	%rd, %r11, #%c12, #%c2
reg:	ZEXT(SLICE(reg, sh), sh)	[1] => 	ubfx	%rd, %r11, #%c12, #%c2
reg:	SEXT(SLICE(reg, sh), sh)	[1] => 	sbfx	%rd, %r11, #%c12, #%c2

reg:	SLICE.B(reg, sh)		[1] => 	ubfx	%rd, %r1, #%c2, #8
reg:	SLICE.H(reg, sh)		[1] => 	ubfx	%rd, %r1, #%c2, #16
reg:	SLICE.L(reg, sh)		[1] => 	ubfx	%rd, %r1, #%c2, #32
reg:	SLICE.L(reg, zero)		[0] == %r0

//// compare
reg:	SET_EQ(condf, zero)	[1] => cset	%rd, %a1
reg:	SET_NE(condt, zero)	[1] => cset	%rd, %a1
reg:	ZEXT(condt, sh)		[1] => cset	%rd, %a1

tsteq:	SET_EQ(reg, simm)	[1] => cmp	%r1, #%c2
tsteq:	SET_EQ(reg, areg)	[1] => cmp	%r1, %a2
tsteq:	SET_EQ(areg, reg)	[1] => cmp	%r2, %a1
tstne:	SET_NE(reg, simm)	[1] => cmp	%r1, #%c2
tstne:	SET_NE(reg, areg)	[1] => cmp	%r1, %a2
tstne:	SET_NE(areg, reg)	[1] => cmp	%r2, %a1

tstlt:	SET_LT(reg, simm)	[1] => cmp	%r1, #%c2
tstlt:	SET_LT(reg, areg)	[1] => cmp	%r1, %a2
tstgt:	SET_LT(areg, reg)	[1] => cmp	%r2, %a1
tstle:	SET_LE(reg, simm)	[1] => cmp	%r1, #%c2
tstle:	SET_LE(reg, areg)	[1] => cmp	%r1, %a2
tstge:	SET_LE(areg, reg)	[1] => cmp	%r2, %a1
tstgt:	SET_GT(reg, simm)	[1] => cmp	%r1, #%c2
tstgt:	SET_GT(reg, areg)	[1] => cmp	%r1, %a2
tstlt:	SET_GT(areg, reg)	[1] => cmp	%r2, %a1
tstge:	SET_GE(reg, simm)	[1] => cmp	%r1, #%c2
tstge:	SET_GE(reg, areg)	[1] => cmp	%r1, %a2
tstle:	SET_GE(areg, reg)	[1] => cmp	%r2, %a1

tstls:	SET_BE(reg, simm)	[1] => cmp	%r1, #%c2
tstls:	SET_BE(reg, areg)	[1] => cmp	%r1, %a2
tsths:	SET_BE(areg, reg)	[1] => cmp	%r2, %a1
tstlo:	SET_B(reg, simm)	[1] => cmp	%r1, #%c2
tstlo:	SET_B(reg, areg)	[1] => cmp	%r1, %a2
tsthi:	SET_B(areg, reg)	[1] => cmp	%r2, %a1
tsths:	SET_AE(reg, simm)	[1] => cmp	%r1, #%c2
tsths:	SET_AE(reg, areg)	[1] => cmp	%r1, %a2
tstls:	SET_AE(areg, reg)	[1] => cmp	%r2, %a1
tsthi:	SET_A(reg, simm)	[1] => cmp	%r1, #%c2
tsthi:	SET_A(reg, areg)	[1] => cmp	%r1, %a2
tstlo:	SET_A(areg, reg)	[1] => cmp	%r2, %a1

//// compare negative
tsteq:	SET_EQ(reg, NEG(areg))	[1] => cmn	%r1, %a2
tsteq:	SET_EQ(areg, NEG(reg))	[1] => cmn	%r2, %a1
tsteq:	SET_EQ(NEG(reg), simm)	[1] => cmn	%r1, #%c2
tsteq:	SET_EQ(NEG(reg), areg)	[1] => cmn	%r1, %a2
tsteq:	SET_EQ(NEG(areg), reg)	[1] => cmn	%r2, %a1
tstne:	SET_NE(reg, NEG(areg))	[1] => cmn	%r1, %a2
tstne:	SET_NE(areg, NEG(reg))	[1] => cmn	%r2, %a1
tstne:	SET_NE(NEG(reg), simm)	[1] => cmn	%r1, #%c2
tstne:	SET_NE(NEG(reg), areg)	[1] => cmn	%r1, %a2
tstne:	SET_NE(NEG(areg), reg)	[1] => cmn	%r2, %a1

tsteq:	SET_EQ(reg, nimm)	[1] => cmn	%r1, #%n2
tstne:	SET_NE(reg, nimm)	[1] => cmn	%r1, #%n2
tstlt:	SET_LT(reg, nimm)	[1] => cmn	%r1, #%n2
tstle:	SET_LE(reg, nimm)	[1] => cmn	%r1, #%n2
tstge:	SET_GE(reg, nimm)	[1] => cmn	%r1, #%n2
tstgt:	SET_GT(reg, nimm)	[1] => cmn	%r1, #%n2
tstlo:	SET_B( reg, nimm)	[1] => cmn	%r1, #%n2
tstls:	SET_BE(reg, nimm)	[1] => cmn	%r1, #%n2
tsths:	SET_AE(reg, nimm)	[1] => cmn	%r1, #%n2
tsthi:	SET_A( reg, nimm)	[1] => cmn	%r1, #%n2

// TODO others cmn for non-commutative compares

//// bit tests
tsteq:	AND.L(reg,bimm32)	[1] => tst	%r1, #%c2
tsteq:	AND.Q(reg,bimm64)	[1] => tst	%r1, #%c2
tsteq:	AND(reg,lreg)		[1] => tst	%r1, %a2
tsteq:	AND(lreg,reg)		[1] => tst	%r2, %a1

////
tsteq0:	reg			[1] => cmp	%r0, #0
condt:	tsteq0		== ne
condt:	tsteq		== eq
condt:	tstne		== ne
condt:	tstlt		== lt
condt:	tstle		== le
condt:	tstgt		== gt
condt:	tstge		== ge
condt:	tstlo		== lo
condt:	tstls		== ls
condt:	tsthi		== hi
condt:	tsths		== hs

tstne0:	reg			[1] => cmp	%r0, #0
condf:	tstne0		== eq
condf:	tsteq		== ne
condf:	tstne		== eq
condf:	tstlt		== ge
condf:	tstle		== gt
condf:	tstgt		== le
condf:	tstge		== lt
condf:	tstlo		== hs
condf:	tstls		== hi
condf:	tsthi		== ls
condf:	tsths		== lo


// !!!WARNING!!! broken when more than one ccmp is involved
// !!!WARNING!!! upport for ccmn (register) is missing
tsteq:	 OR(condf,SET_EQ(reg,imm5))	[1] => ccmp	%r21, #%c22, 4, %a1
tsteq:	 OR(condf,SET_EQ(reg,nmm5))	[1] => ccmn	%r21, #%n22, 4, %a1
tsteq:	 OR(condf,SET_EQ(reg,reg))	[1] => ccmp	%r21, %r22, 4, %a1
tstne:	 OR(condf,SET_NE(reg,imm5))	[1] => ccmp	%r21, #%c22, 0, %a1
tstne:	 OR(condf,SET_NE(reg,nmm5))	[1] => ccmn	%r21, #%n22, 0, %a1
tstne:	 OR(condf,SET_NE(reg,reg))	[1] => ccmp	%r21, %r22, 0, %a1
tstle:	 OR(condf,SET_LE(reg,imm5))	[1] => ccmp	%r21, #%c22, 4, %a1
tstle:	 OR(condf,SET_LE(reg,nmm5))	[1] => ccmn	%r21, #%n22, 4, %a1
tstle:	 OR(condf,SET_LE(reg,reg))	[1] => ccmp	%r21, %r22, 4, %a1
tstlt:	 OR(condf,SET_LT(reg,imm5))	[1] => ccmp	%r21, #%c22, 1, %a1
tstlt:	 OR(condf,SET_LT(reg,nmm5))	[1] => ccmn	%r21, #%n22, 1, %a1
tstlt:	 OR(condf,SET_LT(reg,reg))	[1] => ccmp	%r21, %r22, 1, %a1
tstge:	 OR(condf,SET_GE(reg,imm5))	[1] => ccmp	%r21, #%c22, 0, %a1
tstge:	 OR(condf,SET_GE(reg,nmm5))	[1] => ccmn	%r21, #%n22, 0, %a1
tstge:	 OR(condf,SET_GE(reg,reg))	[1] => ccmp	%r21, %r22, 0, %a1
tstgt:	 OR(condf,SET_GT(reg,imm5))	[1] => ccmp	%r21, #%c22, 0, %a1
tstgt:	 OR(condf,SET_GT(reg,nmm5))	[1] => ccmn	%r21, #%n22, 0, %a1
tstgt:	 OR(condf,SET_GT(reg,reg))	[1] => ccmp	%r21, %r22, 0, %a1
tstls:	 OR(condf,SET_BE(reg,imm5))	[1] => ccmp	%r21, #%c22, 0, %a1
tstls:	 OR(condf,SET_BE(reg,nmm5))	[1] => ccmn	%r21, #%n22, 0, %a1
tstls:	 OR(condf,SET_BE(reg,reg))	[1] => ccmp	%r21, %r22, 0, %a1
tstlo:	 OR(condf,SET_B(reg,imm5))	[1] => ccmp	%r21, #%c22, 0, %a1
tstlo:	 OR(condf,SET_B(reg,nmm5))	[1] => ccmn	%r21, #%n22, 0, %a1
tstlo:	 OR(condf,SET_B(reg,reg))	[1] => ccmp	%r21, %r22, 0, %a1
tsths:	 OR(condf,SET_AE(reg,imm5))	[1] => ccmp	%r21, #%c22, 2, %a1
tsths:	 OR(condf,SET_AE(reg,nmm5))	[1] => ccmn	%r21, #%n22, 2, %a1
tsths:	 OR(condf,SET_AE(reg,reg))	[1] => ccmp	%r21, %r22, 2, %a1
tsthi:	 OR(condf,SET_A(reg,imm5))	[1] => ccmp	%r21, #%c22, 2, %a1
tsthi:	 OR(condf,SET_A(reg,nmm5))	[1] => ccmn	%r21, #%n22, 2, %a1
tsthi:	 OR(condf,SET_A(reg,reg))	[1] => ccmp	%r21, %r22, 2, %a1

tsteq:	AND(condt,SET_EQ(reg,imm5))	[1] => ccmp	%r21, #%c22, 0, %a1
tsteq:	AND(condt,SET_EQ(reg,nmm5))	[1] => ccmn	%r21, #%n22, 0, %a1
tsteq:	AND(condt,SET_EQ(reg,reg))	[1] => ccmp	%r21, %r22, 0, %a1
tstne:	AND(condt,SET_NE(reg,imm5))	[1] => ccmp	%r21, #%c22, 4, %a1
tstne:	AND(condt,SET_NE(reg,nmm5))	[1] => ccmn	%r21, #%n22, 4, %a1
tstne:	AND(condt,SET_NE(reg,reg))	[1] => ccmp	%r21, %r22, 4, %a1
tstle:	AND(condt,SET_LE(reg,imm5))	[1] => ccmp	%r21, #%c22, 0, %a1
tstle:	AND(condt,SET_LE(reg,nmm5))	[1] => ccmn	%r21, #%n22, 0, %a1
tstle:	AND(condt,SET_LE(reg,reg))	[1] => ccmp	%r21, %r22, 0, %a1
tstlt:	AND(condt,SET_LT(reg,imm5))	[1] => ccmp	%r21, #%c22, 0, %a1
tstlt:	AND(condt,SET_LT(reg,nmm5))	[1] => ccmn	%r21, #%n22, 0, %a1
tstlt:	AND(condt,SET_LT(reg,reg))	[1] => ccmp	%r21, %r22, 0, %a1
tstge:	AND(condt,SET_GE(reg,imm5))	[1] => ccmp	%r21, #%c22, 1, %a1
tstge:	AND(condt,SET_GE(reg,nmm5))	[1] => ccmn	%r21, #%n22, 1, %a1
tstge:	AND(condt,SET_GE(reg,reg))	[1] => ccmp	%r21, %r22, 1, %a1
tstgt:	AND(condt,SET_GT(reg,imm5))	[1] => ccmp	%r21, #%c22, 4, %a1
tstgt:	AND(condt,SET_GT(reg,nmm5))	[1] => ccmn	%r21, #%n22, 4, %a1
tstgt:	AND(condt,SET_GT(reg,reg))	[1] => ccmp	%r21, %r22, 4, %a1
tstls:	AND(condt,SET_BE(reg,imm5))	[1] => ccmp	%r21, #%c22, 2, %a1
tstls:	AND(condt,SET_BE(reg,nmm5))	[1] => ccmn	%r21, #%n22, 2, %a1
tstls:	AND(condt,SET_BE(reg,reg))	[1] => ccmp	%r21, %r22, 2, %a1
tstlo:	AND(condt,SET_B(reg,imm5))	[1] => ccmp	%r21, #%c22, 2, %a1
tstlo:	AND(condt,SET_B(reg,nmm5))	[1] => ccmn	%r21, #%n22, 2, %a1
tstlo:	AND(condt,SET_B(reg,reg))	[1] => ccmp	%r21, %r22, 2, %a1
tsths:	AND(condt,SET_AE(reg,imm5))	[1] => ccmp	%r21, #%c22, 0, %a1
tsths:	AND(condt,SET_AE(reg,nmm5))	[1] => ccmn	%r21, #%n22, 0, %a1
tsths:	AND(condt,SET_AE(reg,reg))	[1] => ccmp	%r21, %r22, 0, %a1
tsthi:	AND(condt,SET_A(reg,imm5))	[1] => ccmp	%r21, #%c22, 0, %a1
tsthi:	AND(condt,SET_A(reg,nmm5))	[1] => ccmn	%r21, #%n22, 0, %a1
tsthi:	AND(condt,SET_A(reg,reg))	[1] => ccmp	%r21, %r22, 0, %a1


:	CBR(condt)		[1] => b%a1	%b
:	CBR(reg)		[1] => cbnz	%r1, %b

cbne:	SET_NE(reg, zero)	    == %r1
cbeq:	SET_EQ(reg, zero)	    == %r1
:	CBR(cbne)		[1] => cbnz	%a1, %b
:	CBR(cbeq)		[1] => cbz	%a1, %b

// FIXME: tbz, tbnz
:	CBR(AND(reg,bit))	[1] => tbnz	%r11, #%c:log2:12, %b

:	BR			[1] => b	%b
:	COMPUTEDGOTO(reg)	[1] => br	%r1

//// select
reg:	condt				[1] => cset	%rd, %a0
reg:	SEL.L(condf, zero, ones32)	[1] => csetm	%rd, %a1
reg:	SEL.Q(condf, zero, ones64)	[1] => csetm	%rd, %a1
reg:	SEL.L(condt, ones32, zero)	[1] => csetm	%rd, %a1
reg:	SEL.Q(condt, ones64, zero)	[1] => csetm	%rd, %a1

reg:	SEL(condt, zreg, zreg)		[1] => csel	%rd, %r2, %r3, %a1

reg:	SEL(condt, zreg, ADD(reg,one))	[1] => csinc	%rd, %r2, %r31, %a1
reg:	SEL(condf, ADD(reg, one),zero)	[1] => csinc	%rd, %r21, %r3, %a1
reg:	SEL(condt, reg, one)		[1] => csinc	%rd, %r2, %rz, %a1
reg:	SEL(condf, one, reg)		[1] => csinc	%rd, %r3, %rz, %a1

reg:	SEL(condt, zreg, NOT(reg))	[1] => csinv	%rd, %r2, %r31, %a1
reg:	SEL(condf, NOT(reg), zreg)	[1] => csinv	%rd, %r21, %r3, %a1

reg:	SEL(condt, zreg, NEG(reg))	[1] => csneg	%rd, %r2, %r31, %a1
reg:	SEL(condf, NEG(reg), zreg)	[1] => csneg	%rd, %r21, %r3, %a1

//// builtins
reg:	BSWAP.H(reg)		[1] => rev16	%rd, %r1
reg:	BSWAP.L(reg)		[1] => rev	%rd, %r1
reg:	BSWAP.Q(reg)		[1] => rev	%rd, %r1

reg:	CLS(reg)		[1] => cls	%rd, %r1
reg:	CLZ(reg)		[1] => clz	%rd, %r1
reg:	CTZ(reg)		[2] => rbit	%rd, %r1; clz	%rd, %rd

//// load and store
// FIXME: need to add pre and post writeback modes

reg:	SYMADDR(GSYM)		[2] => adrp	%rd, %l1; add	%rd, %rd, :lo12:%l1
reg:	SYMADDR(LSYM)		[1] => add	%rd, sp, SP@%c1

addr:	reg			    == %r0
addr:	ADD(reg,reg)		    == %r1, %r2
addr:	ADD(reg,ZEXT(reg,#L))	    == %r1, %r21, uxtw
addr:	ADD(ZEXT(reg,#L),reg)	    == %r2, %r11, uxtw
addr:	ADD(reg,SEXT(reg,#L))	    == %r1, %r21, sxtw
addr:	ADD(SEXT(reg,#L),reg)	    == %r2, %r11, sxtw

addr8:	addr
addr8:	ADD(reg, pimm8)			    == %r1, #%c2
addr8:	ADD(reg,SHL(reg, #3))		    == %r1, %r21, lsl #3
addr8:	ADD(SHL(reg, #3), reg)		    == %r2, %r11, lsl #3
addr8:	ADD(reg,SHL(SEXT(reg,#L),#3))	== %r1, %r21, sxtw #3
addr8:	ADD(SHL(SEXT(reg,#L),#3),reg)	== %r2, %r11, sxtw #3
addr8:	ADD(reg,SHL(ZEXT(reg,#L),#3))	== %r1, %r21, uxtw #3
addr8:	ADD(SHL(ZEXT(reg,#L),#3),reg)	== %r2, %r11, uxtw #3
reg:	LOAD.Q(addr8)			[4] => ldr	%rd, [%a1]
:	STORE.Q(addr8,zreg)		[1] => str	%r2, [%a1]

addr4:	addr
addr4:	ADD(reg, pimm4)			== %r1, #%c2
addr4:	ADD(reg,SHL(reg, #2))		== %r1, %r21, lsl #2
addr4:	ADD(SHL(reg, #2),reg)		== %r2, %r11, lsl #2
addr4:	ADD(reg,SHL(SEXT(reg,#L),#2))	== %r1, %r21, sxtw #2
addr4:	ADD(SHL(SEXT(reg,#L),#2),reg)	== %r2, %r11, sxtw #2
addr4:	ADD(reg,SHL(ZEXT(reg,#L),#2))	== %r1, %r21, uxtw #2
addr4:	ADD(SHL(ZEXT(reg,#L),#2),reg)	== %r2, %r11, uxtw #2
ldl:	LOAD.L(addr4)			== %a1
ldl:	LOAD2.L(addr4)			== %a1
reg:	ldl				[4] => ldr	%rd, [%a0]
reg:	ZEXT(ldl,#L)			[4] => ldr	%rd, [%a1]
reg:	SEXT(ldl,#L)			[4] => ldrsw	%rd, [%a1]
:	STORE.L(addr4,zreg)		[1] => str	%r2, [%a1]
:	STORE.L(addr4,TRUNC(reg,CONST))	[1] => str	%r21, [%a1]
:	STORE2.L(addr4,zreg)		[1] => str	%r2, [%a1]

addr2:	addr
addr2:	ADD(reg, pimm2)			== %r1, #%c2
addr2:	ADD(reg,SHL(reg, #1))		== %r1, %r21, lsl #1
addr2:	ADD(SHL(reg, #1), reg)		== %r2, %r11, lsl #1
addr2:	ADD(reg,SHL(SEXT(reg,#L),#1))	== %r1, %r21, sxtw #1
addr2:	ADD(SHL(SEXT(reg,#L),#1),reg)	== %r2, %r11, sxtw #1
addr2:	ADD(reg,SHL(ZEXT(reg,#L),#1))	== %r1, %r21, uxtw #1
addr2:	ADD(SHL(ZEXT(reg,#L),#1),reg)	== %r2, %r11, uxtw #1
ldh:	LOAD.H(addr2)			== %a1
reg:	ldh				[4] => ldrh	%rd, [%a0]
reg:	ZEXT(ldh,#H)			[4] => ldrh	%rd, [%a1]
reg:	SEXT(ldh,#H)			[4] => ldrsh	%rd, [%a1]
:	STORE.H(addr2,zreg)		[1] => strh	%r2, [%a1]
:	STORE.H(addr2,TRUNC(reg,CONST))	[1] => strh	%r21, [%a1]

addr1:	addr
addr1:	ADD(reg, pimm1)			== %r1, #%c2
ldb:	LOAD.B(addr1)			== %a1
reg:	ldb				[4] => ldrb	%rd, [%a0]
reg:	ZEXT(ldb,#B)			[4] => ldrb	%rd, [%a1]
reg:	SEXT(ldb,#B)			[4] => ldrsb	%rd, [%a1]
:	STORE.B(addr1,zreg)		[1] => strb	%r2, [%a1]
:	STORE.B(addr1,TRUNC(reg,CONST))	[1] => strb	%r21, [%a1]


simm7l:	CONST		if masked_range(%c, 2, -256, 252)
simm7q:	CONST		if masked_range(%c, 2, -512, 504)

addr7l:	reg				== %r0
addr7l:	ADD(reg, simm7l)		== %r1, #%c2
addr7q:	reg				== %r0
addr7q:	ADD(reg, simm7q)		== %r1, #%c2

preg:	ARG
preg:	REG

reg:	LOAD2.L(addr7l)			[4] => ldp	%rd:lo, %rd:hi, [%a1]
reg:	LOAD2.Q(addr7q)			[4] => ldp	%rd:lo, %rd:hi, [%a1]
:	STORE2.L(addr7l, zero)		[1] => stp	%r2, %r0, [%a1]
:	STORE2.L(addr7l, preg)		[1] => stp	%r2:lo, %r2:hi, [%a1]
:	STORE2.Q(addr7q, zero)		[1] => stp	%r0, %r0, [%a1]
:	STORE2.Q(addr7q, preg)		[1] => stp	%r2:lo, %r2:hi, [%a1]

:	STOREMEM(reg, LOADMEM(reg))	[30]=> bl	memcpy(%r1, %r21, #%#)


//// control flow
reg:	CALL			[1] => bl	%l1 -> %rd
reg:	CALLR(reg)		[1] => blr	%r1 -> %rd
freg:	CALL			[1] => bl	%l1 -> %rd
freg:	CALLR(reg)		[1] => blr	%r1 -> %rd
tcall:	CALL			[1] => b	%l1
tcall:	CALLR(reg)		[1] => br	%r1

:	RET(tcall)		[0]	// premature tail call optimization
:	RET(reg)		[1] => ret	(-> %r1)
:	RETVOID			[1] => ret

////////////////////////////////////////////////////////////////////////
//// floating-point

freg:	ARG
freg:	REG

:	freg
:	RET(freg)		[1] => ret	%r1

freg:	FLOAD(addr)		[2] => ldr	%rd, %a1
:	FSTORE(addr, freg)	[2] => str	%r2, %a1

freg:	SETFVAL			[4] => fmv	%rd, %f	// FIXME
freg:	COPY(freg)		[1] => fmv	%rd, %r1

freg:	UCVTF(reg, reg)		[3] => ucvtf	%rd, %r1
freg:	SCVTF(reg, reg)		[3] => scvtf	%rd, %r1
freg:	FCVTF(freg, freg)	[3] => fcvt	%rd, %r1
reg:	FCVTU(reg, freg)	[3] => fcvtzu	%rd, %r1
reg:	FCVTS(reg, freg)	[3] => fcvtzs	%rd, %r1
// FIXME

freg:	FNEG(freg)		[3] => fneg	%rd, %r1
//freg:	FABS(freg)		[3] => fabs	%rd, %r1
freg:	FADD(freg, freg)	[5] => fadd	%rd, %r1, %r2
freg:	FSUB(freg, freg)	[5] => fsub	%rd, %r1, %r2
freg:	FMUL(freg, freg)	[5] => fmul	%rd, %r1, %r2
freg:	FDIV(freg, freg)	[32] => fdiv	%rd, %r1, %r2
//freg:	FMIN(freg, freg)	[5] => fmin	%rd, %r1, %r2
//freg:	FMAX(freg, freg)	[5] => fmax	%rd, %r1, %r2
//freg:	FSQRT(freg)		[32] => fsqrt	%rd, %r1

freg:	FNEG(FMUL(freg, freg))	[5] => fnmul	%rd, %r11, %r12
freg:	FMUL(FNEG(freg), freg)	[5] => fnmul	%rd, %r11, %r2
freg:	FMUL(freg, FNEG(freg))	[5] => fnmul	%rd, %r1, %r21

freg:	FADD(FMUL(freg, freg), freg)	[4] => fmadd	%rd, %r11, %r12, %r2
freg:	FADD(freg, FMUL(freg, freg))	[4] => fmadd	%rd, %r21, %r22, %r1
freg:	FSUB(freg, FMUL(freg, freg))	[4] => fmsub	%rd, %r21, %r22, %r1
freg:	FSUB(FMUL(freg, freg), freg)	[4] => fnmsub	%rd, %r11, %r12, %r2
freg:	FADD(FMUL(FNEG(freg),freg),freg)[4] => fnmsub	%rd, %r111, %r12, %r2
freg:	FSUB(FMUL(FNEG(freg),freg),freg)[4] => fnmadd	%rd, %r111, %r12, %r2
freg:	FSUB(FNEG(freg),FMUL(freg,freg))[4] => fnmadd	%rd, %r21, %r22, %r11
freg:	FNEG(FADD(FMUL(freg,freg),freg))[4] => fnmadd	%rd, %r111, %r112, %r12
freg:	FNEG(FADD(freg,FMUL(freg,freg)))[4] => fnmadd	%rd, %r121, %r122, %r11

tstoeq:	FCMP_OEQ(freg, freg)	[3] => fcmp	%r1, %r2
tstune:	FCMP_UNE(freg, freg)	[3] => fcmp	%r1, %r2
tstolt:	FCMP_OLT(freg, freg)	[3] => fcmp	%r1, %r2
tstole:	FCMP_OLE(freg, freg)	[3] => fcmp	%r1, %r2
tstogt:	FCMP_OGT(freg, freg)	[3] => fcmp	%r1, %r2
tstoge:	FCMP_OGE(freg, freg)	[3] => fcmp	%r1, %r2
tstult:	FCMP_ULT(freg, freg)	[3] => fcmp	%r1, %r2
tstule:	FCMP_ULE(freg, freg)	[3] => fcmp	%r1, %r2
tstugt:	FCMP_UGT(freg, freg)	[3] => fcmp	%r1, %r2
tstuge:	FCMP_UGE(freg, freg)	[3] => fcmp	%r1, %r2

condt:	tstoeq == eq
condt:	tstune == ne
condt:	tstolt == mi
condt:	tstole == ls
condt:	tstogt == gt
condt:	tstoge == ge

condt:	tstult == lt
condt:	tstule == le
condt:	tstugt == hi
condt:	tstuge == pl

condf:	tstoeq == ne
condf:	tstune == eq
condf:	tstolt == pl
condf:	tstole == hi
condf:	tstogt == le
condf:	tstoge == lt
